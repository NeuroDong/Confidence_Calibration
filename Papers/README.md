# 📕 Table of Contents
- [📕 Table of Contents](#-table-of-contents)
- [Calibration Metric](#calibration-metric)
- [Calibration Method](#calibration-method)
  - [Train-time Calibration](#train-time-calibration)
  - [Post-hoc Calibration](#post-hoc-calibration)
    - [Parametric Method](#parametric-method)
    - [Non-parametric Method](#non-parametric-method)
    - [Mixed Method](#mixed-method)
- [Calibration under Distribution Shift](#calibration-under-distribution-shift)
  - [Calibration under Label Shift](#calibration-under-label-shift)
    - [Calibration under Class Imbalance](#calibration-under-class-imbalance)
  - [Calibration under Covariate Shift](#calibration-under-covariate-shift)
  - [Calibration under Joint Shift](#calibration-under-joint-shift)
- [How to Update Citations](#how-to-update-citations)

# Calibration Metric
| Paper | Source | Year| Code| Citations |
|-------|-------|-------|-------|:--:|
|[Combining Priors with Experience: Confidence Calibration Based on Binomial Process Modeling](https://ojs.aaai.org/index.php/AAAI/article/view/33792)|AAAI|2025|[![Star](https://img.shields.io/github/stars/NeuroDong/TCEbpm.svg?style=social&label=Star)](https://github.com/NeuroDong/TCEbpm)| [![Citations](badges/Combining_Priors_with_Experience__Confidence_Calibration_Based_on_Binomial_Process_Modeling.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Combining+Priors+with+Experience%3A+Confidence+Calibration+Based+on+Binomial+Process+Modeling&btnG=) |
|[Smooth ECE: Principled Reliability Diagrams via Kernel Smoothing](https://arxiv.org/abs/2309.12236)|ICLR|2024|[![Star](https://img.shields.io/github/stars/apple/ml-calibration.svg?style=social&label=Star)](https://github.com/apple/ml-calibration)| [![Citations](badges/Smooth_ECE__Principled_Reliability_Diagrams_via_Kernel_Smoothing.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Smooth+ECE%3A+Principled+Reliability+Diagrams+via+Kernel+Smoothing&btnG=) |
|[Proximity-Informed Calibration for Deep Neural Networks](https://arxiv.org/abs/2306.04590)|NeurIPS|2023|[![Star](https://img.shields.io/github/stars/MiaoXiong2320/ProximityBias-Calibration.svg?style=social&label=Star)](https://github.com/MiaoXiong2320/ProximityBias-Calibration)| [![Citations](badges/Proximity-Informed_Calibration_for_Deep_Neural_Networks.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Proximity-Informed+Calibration+for+Deep+Neural+Networks&btnG=) |
|[A Unifying Theory of Distance from Calibration](https://arxiv.org/abs/2211.16886)|STOC|2023|None| [![Citations](badges/A_Unifying_Theory_of_Distance_from_Calibration.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=A+Unifying+Theory+of+Distance+from+Calibration&btnG=) |
|[Beyond calibration: estimating the grouping loss of modern neural networks](https://arxiv.org/abs/2210.16315)|ICLR|2023|[![Star](https://img.shields.io/github/stars/aperezlebel/beyond_calibration.svg?style=social&label=Star)](https://github.com/aperezlebel/beyond_calibration)| [![Citations](badges/Beyond_calibration__estimating_the_grouping_loss_of_modern_neural_networks.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Beyond+calibration%3A+estimating+the+grouping+loss+of+modern+neural+networks&btnG=) |
|[Consistent and Asymptotically Unbiased Estimation of Proper Calibration Errors](https://arxiv.org/abs/2312.08589)|AISTATS|2023|[![Star](https://img.shields.io/github/stars/tpopordanoska/proper-calibration-error.svg?style=social&label=Star)](https://github.com/tpopordanoska/proper-calibration-error)| [![Citations](badges/Consistent_and_Asymptotically_Unbiased_Estimation_of_Proper_Calibration_Errors.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Consistent+and+Asymptotically+Unbiased+Estimation+of+Proper+Calibration+Errors&btnG=) |
|[A Consistent and Differentiable Lp Canonical Calibration Error Estimator](https://arxiv.org/abs/2210.07810)|NeurIPS|2022|[![Star](https://img.shields.io/github/stars/tpopordanoska/ece-kde.svg?style=social&label=Star)](https://github.com/tpopordanoska/ece-kde)| [![Citations](badges/A_Consistent_and_Differentiable_Lp_Canonical_Calibration_Error_Estimator.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=A+Consistent+and+Differentiable+Lp+Canonical+Calibration+Error+Estimator&btnG=) |
|[T-Cal: An optimal test for the calibration of predictive models](https://arxiv.org/abs/2203.01850)|JMLR|2022|[![Star](https://img.shields.io/github/stars/dh7401/T-Cal.svg?style=social&label=Star)](https://github.com/dh7401/T-Cal)| [![Citations](badges/T-Cal__An_optimal_test_for_the_calibration_of_predictive_models.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=T-Cal%3A+An+optimal+test+for+the+calibration+of+predictive+models&btnG=) |
|[Metrics of calibration for probabilistic predictions](https://arxiv.org/abs/2205.09680)|JMLR|2022|[![Star](https://img.shields.io/github/stars/facebookresearch/ecevecce.svg?style=social&label=Star)](https://github.com/facebookresearch/ecevecce)| [![Citations](badges/Metrics_of_calibration_for_probabilistic_predictions.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Metrics+of+calibration+for+probabilistic+predictions&btnG=) |
|[Mitigating Bias in Calibration Error Estimation](https://proceedings.mlr.press/v151/roelofs22a.html)|AISTATS|2022|[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?style=for-the-badge&logo=github)](https://github.com/google-research/google-research/tree/master/caltrain)| [![Citations](badges/Mitigating_Bias_in_Calibration_Error_Estimation.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Mitigating+Bias+in+Calibration+Error+Estimation&btnG=) |
|[Stable reliability diagrams for probabilistic classifiers](https://www.pnas.org/doi/abs/10.1073/pnas.2016191118)|PNAS|2021|[![Star](https://img.shields.io/github/stars/TimoDimi/replication_DGJ20.svg?style=social&label=Star)](https://github.com/TimoDimi/replication_DGJ20)|[![Citations](badges/Stable_reliability_diagrams_for_probabilistic_classifiers.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Stable+reliability+diagrams+for+probabilistic+classifiers&btnG=)|
|[Distribution-Free Calibration Guarantees for Histogram Binning without Sample Splitting](https://proceedings.mlr.press/v139/gupta21b.html)|ICML|2021|[![Star](https://img.shields.io/github/stars/aigen/df-posthoc-calibration.svg?style=social&label=Star)](https://github.com/aigen/df-posthoc-calibration)| [![Citations](badges/Distribution-Free_Calibration_Guarantees_for_Histogram_Binning_without_Sample_Splitting.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Distribution-Free+Calibration+Guarantees+for+Histogram+Binning+without+Sample+Splitting&btnG=) |
|[Calibration of Neural Networks using Splines](https://arxiv.org/abs/2006.12800)|ICLR|2021|[![Star](https://img.shields.io/github/stars/kartikgupta-at-anu/spline-calibration.svg?style=social&label=Star)](https://github.com/kartikgupta-at-anu/spline-calibration)| [![Citations](badges/Calibration_of_Neural_Networks_using_Splines.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Calibration+of+Neural+Networks+using+Splines&btnG=) | 
|[Evaluating model calibration in classification](https://proceedings.mlr.press/v89/vaicenavicius19a.html)|AISTATS|2019|[![Star](https://img.shields.io/github/stars/uu-sml/calibration.svg?style=social&label=Star)](https://github.com/uu-sml/calibration)| [![Citations](badges/Evaluating_model_calibration_in_classification.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Evaluating+model+calibration+in+classification+Vaicenavicius&btnG=) |
|[Verified Uncertainty Calibration](https://proceedings.neurips.cc/paper/2019/hash/f8c0c968632845cd133308b1a494967f-Abstract.html)|NeurIPS|2019|[![Star](https://img.shields.io/github/stars/p-lambda/verified_calibration.svg?style=social&label=Star)](https://github.com/p-lambda/verified_calibration)| [![Citations](badges/Verified_Uncertainty_Calibration.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Verified+Uncertainty+Calibration&btnG=) | 
|[Trainable Calibration Measures for Neural Networks from Kernel Mean Embeddings](https://proceedings.mlr.press/v80/kumar18a.html)| ICML | 2018 |[![Star](https://img.shields.io/github/stars/aviralkumar2907/MMCE.svg?style=social&label=Star)](https://github.com/aviralkumar2907/MMCE)| [![Citations](badges/Trainable_Calibration_Measures_for_Neural_Networks_from_Kernel_Mean_Embeddings.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Trainable+calibration+measures+for+neural+networks+from+kernel+mean+embeddings&btnG=) | 
|[Calibrated Structured Prediction](https://proceedings.neurips.cc/paper/2015/hash/52d2752b150f9c35ccb6869cbf074e48-Abstract.html)| NeurIPS | 2015 | None | [![Citations](badges/Calibrated_Structured_Prediction.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Calibrated+Structured+Prediction&btnG=) | 


# Calibration Method
## Train-time Calibration
| Paper | Name| Source | Year| Code| Citations |
|-------|-------|-------|-------|-------|:--:|
|[Calibration Bottleneck: Over-compressed Representations are Less Calibratable](https://proceedings.mlr.press/v235/wang24cm.html)|PLP|ICML|2024|[![Star](https://img.shields.io/github/stars/dengbaowang/PLP.svg?style=social&label=Star)](https://github.com/dengbaowang/PLP)|[![Citations](badges/Calibration_Bottleneck__Over-compressed_Representations_are_Less_Calibratable.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Calibration+Bottleneck%3A+Over-compressed+Representations+are+Less+Calibratable&btnG=)|
|[Meta-Calibration: Learning of Model Calibration Using Differentiable Expected Calibration Error](https://openreview.net/forum?id=R2hUure38l)| DECE | TMLR | 2023 | [![Star](https://img.shields.io/github/stars/ondrejbohdal/meta-calibration.svg?style=social&label=Star)](https://github.com/ondrejbohdal/meta-calibration) | [![Citations](badges/Meta-Calibration__Learning_of_Model_Calibration_Using_Differentiable_Expected_Calibration_Error.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Meta-Calibration%3A+Learning+of+Model+Calibration+Using+Differentiable+Expected+Calibration+Error&btnG=) |
|[Soft Calibration Objectives for Neural Networks](https://proceedings.neurips.cc/paper/2021/hash/f8905bd3df64ace64a68e154ba72f24c-Abstract.html)|Soft-Binned ECE|NeurIPS|2021|[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?style=for-the-badge&logo=github)](https://github.com/google/uncertainty-baselines/tree/main/experimental/caltrain)|[![Citations](badges/Soft_Calibration_Objectives_for_Neural_Networks.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Soft+Calibration+Objectives+for+Neural+Networks&btnG=)|
|[When Does Label Smoothing Help?](https://proceedings.neurips.cc/paper_files/paper/2019/hash/f1748d6b0fd9d439f71450117eba2725-Abstract.html?ref=gojiberries.io)|Label Smoothing|NeurIPS|2019|None|[![Citations](badges/When_Does_Label_Smoothing_Help_.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=When+does+label+smoothing+help%3F&btnG=)|


## Post-hoc Calibration
### Parametric Method
| Paper | Name| Source | Year| Code| Citations |
|-------|-------|-------|-------|-------|:--:|
|[On Calibration of Modern Neural Networks](https://proceedings.mlr.press/v70/guo17a.html)|Temperature Scaling|ICML|2017|None|[![Citations](badges/On_Calibration_of_Modern_Neural_Networks.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=On+Calibration+of+Modern+Neural+Networks&btnG=)|
|[Intra Order-Preserving Functions for Calibration of Multi-Class Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2020/hash/9bc99c590be3511b8d53741684ef574c-Abstract.html)|Intra Order-Preserving Calibration|NeurIPS|2020|None|[![Citations](badges/Intra_Order-Preserving_Functions_for_Calibration_of_Multi-Class_Neural_Networks.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Intra+Order-Preserving+Functions+for+Calibration+of+Multi-Class+Neural+Networks&btnG=)|
|[Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet calibration](https://proceedings.neurips.cc/paper/2019/hash/8ca01ea920679a0fe3728441494041b9-Abstract.html)|Dirichlet Calibration|NeurIPS|2019|[![Star](https://img.shields.io/github/stars/dirichletcal/dirichletcal.github.io.svg?style=social&label=Star)](https://github.com/dirichletcal/dirichletcal.github.io)|[![Citations](badges/Beyond_temperature_scaling__Obtaining_well-calibrated_multi-class_probabilities_with_dirichlet_calibration.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Beyond+temperature+scaling%3A+Obtaining+well-calibrated+multi-class+probabilities+with+dirichlet+calibration&btnG=)|
|[Beta calibration: a well-founded and easily implemented improvement on logistic calibration for binary classiﬁers](https://proceedings.mlr.press/v54/kull17a.html)|Beta Calibration|AISTATS|2017|[![Star](https://img.shields.io/github/stars/betacal/betacal.github.io.svg?style=social&label=Star)](https://github.com/betacal/betacal.github.io)|[![Citations](badges/Beta_calibration__a_well-founded_and_easily_implemented_improvement_on_logistic_calibration_for_binary_classi_ers.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Beta+calibration%3A+a+well-founded+and+easily+implemented+improvement+on+logistic+calibration+for+binary+classifiers&btnG=)|
|[Probabilistic Outputs for Support Vector Machines and Comparisons to Regularized Likelihood Methods](https://www.researchgate.net/profile/John-Platt-2/publication/2594015_Probabilistic_Outputs_for_Support_Vector_Machines_and_Comparisons_to_Regularized_Likelihood_Methods/links/004635154cff5262d6000000/Probabilistic-Outputs-for-Support-Vector-Machines-and-Comparisons-to-Regularized-Likelihood-Methods.pdf)|Platt Scaling|Advances in Large Margin Classifiers|1999|None|[![Citations](badges/Probabilistic_Outputs_for_Support_Vector_Machines_and_Comparisons_to_Regularized_Likelihood_Methods.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Probabilistic+Outputs+for+Support+Vector+Machines+and+Comparisons+to+Regularized+Likelihood+Methods&btnG=)|

### Non-parametric Method
| Paper | Name| Source | Year| Code| Citations |
|-------|-------|-------|-------|-------|:--:|
|[Obtaining Well Calibrated Probabilities Using Bayesian Binning](https://ojs.aaai.org/index.php/AAAI/article/view/9602)|Bayesian Binning|AAAI|2015|None|[![Citations](badges/Obtaining_Well_Calibrated_Probabilities_Using_Bayesian_Binning.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Obtaining+Well+Calibrated+Probabilities+Using+Bayesian+Binning&btnG=)|
|[Obtaining calibrated probability estimates from decision trees and naive bayesian classifiers](https://dl.acm.org/doi/abs/10.5555/645530.655658)|Histogram Binning|ICML|2001|None|[![Citations](badges/Obtaining_calibrated_probability_estimates_from_decision_trees_and_naive_bayesian_classifiers.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Obtaining+calibrated+probability+estimates+from+decision+trees+and+naive+bayesian+classifiers&btnG=)|
|[Transforming classifier scores into accurate multiclass probability estimates](https://dl.acm.org/doi/abs/10.1145/775047.775151)|Isotonic Regression|KDD|2002|None|[![Citations](badges/Transforming_classifier_scores_into_accurate_multiclass_probability_estimates.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Transforming+classifier+scores+into+accurate+multiclass+probability+estimates&btnG=)|

### Mixed Method
| Paper | Name| Source | Year| Code| Citations |
|-------|-------|-------|-------|-------|:--:|
|[Mix-n-Match : Ensemble and Compositional Methods for Uncertainty Calibration in Deep Learning](https://proceedings.mlr.press/v119/zhang20k.html)|Mix-n-Match|ICML|2020|[![Star](https://img.shields.io/github/stars/zhang64-llnl/Mix-n-Match-Calibration.svg?style=social&label=Star)](https://github.com/zhang64-llnl/Mix-n-Match-Calibration)|[![Citations](badges/Mix-n-Match___Ensemble_and_Compositional_Methods_for_Uncertainty_Calibration_in_Deep_Learning.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Mix-n-Match+%3A+Ensemble+and+Compositional+Methods+for+Uncertainty+Calibration+in+Deep+Learning&btnG=)|
|[Verified Uncertainty Calibration](https://proceedings.neurips.cc/paper/2019/hash/f8c0c968632845cd133308b1a494967f-Abstract.html)|Scaling-binning|NeurIPS|2020|[![Star](https://img.shields.io/github/stars/p-lambda/verified_calibration.svg?style=social&label=Star)](https://github.com/p-lambda/verified_calibration)|[![Citations](badges/Verified_Uncertainty_Calibration.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Verified+Uncertainty+Calibration&btnG=)|
|[Calibrating User Response Predictions in Online Advertising](https://link.springer.com/chapter/10.1007/978-3-030-67667-4_13)|SIR|ECML-PKDD|2020|None|[![Citations](badges/Calibrating_User_Response_Predictions_in_Online_Advertising.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Calibrating+User+Response+Predictions+in+Online+Advertising&btnG=)|
|[MBCT: Tree-Based Feature-Aware Binning for Individual Uncertainty Calibration](https://dl.acm.org/doi/abs/10.1145/3485447.3512096)|MBCT|WWW|2022|[![Star](https://img.shields.io/github/stars/huangsg1/Tree-Based-Feature-Aware-Binning-for-Individual-Uncertainty-Calibration.svg?style=social&label=Star)](https://github.com/huangsg1/Tree-Based-Feature-Aware-Binning-for-Individual-Uncertainty-Calibration)|[![Citations](badges/MBCT__Tree-Based_Feature-Aware_Binning_for_Individual_Uncertainty_Calibration.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=MBCT%3A+Tree-Based+Feature-Aware+Binning+for+Individual+Uncertainty+Calibration&btnG=)|

# Calibration under Distribution Shift
## Calibration under Label Shift
| Paper | Source | Year| Code| Citations | 
|-------|-------|-------|-------|:--:|
|[LaSCal: Label-Shift Calibration without target labels](https://proceedings.neurips.cc/paper_files/paper/2024/hash/783c5986e1d6112cb4688d9b2105609a-Abstract-Conference.html)| NeurIPS | 2024 |[![Star](https://img.shields.io/github/stars/tpopordanoska/label-shift-calibration.svg?style=social&label=Star)](https://github.com/tpopordanoska/label-shift-calibration)|[![Citations](badges/LaSCal__Label-Shift_Calibration_without_target_labels.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=LaSCal%3A+Label-Shift+Calibration+without+target+labels&btnG=)|
|[Minimum-Risk Recalibration of Classifiers](https://proceedings.neurips.cc/paper_files/paper/2023/hash/dbd6b295535e44f2b8ec0c3f1da7c509-Abstract-Conference.html)| NeurIPS | 2024 | [![Star](https://img.shields.io/github/stars/ZeyuSun/calibration_label_shift.svg?style=social&label=Star)](https://github.com/ZeyuSun/calibration_label_shift)|[![Citations](badges/Minimum-Risk_Recalibration_of_Classifiers.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Minimum-Risk+Recalibration+of+Classifiers&btnG=)|
|[Distribution-free uncertainty quantification for classification under label shift](https://proceedings.mlr.press/v161/podkopaev21a.html)| UAI | 2021 | None | [![Citations](badges/Distribution-free_uncertainty_quantification_for_classification_under_label_shift.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Distribution-free+uncertainty+quantification+for+classification+under+label+shift&btnG=)|
|[Disentangling Label Distribution for Long-tailed Visual Recognition](https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Disentangling_Label_Distribution_for_Long-Tailed_Visual_Recognition_CVPR_2021_paper.html)| ICCV | 2021 | [![Star](https://img.shields.io/github/stars/hyperconnect/LADE.svg?style=social&label=Star)](https://github.com/hyperconnect/LADE) | [![Citations](badges/Disentangling_Label_Distribution_for_Long-tailed_Visual_Recognition.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Disentangling+Label+Distribution+for+Long-tailed+Visual+Recognition&btnG=) |

### Calibration under Class Imbalance
| Paper | Source | Year| Code| Citations | 
|-------|-------|-------|-------|:--:|

## Calibration under Covariate Shift
| Paper | Source | Year| Code| Citations | 
|-------|-------|-------|-------|:--:| 
|[Pseudo-Calibration: Improving Predictive Uncertainty Estimation in Unsupervised Domain Adaptation](https://proceedings.mlr.press/v235/hu24i.html)| ICML | 2024 | [![Star](https://img.shields.io/github/stars/LHXXHB/PseudoCal.svg?style=social&label=Star)](https://github.com/LHXXHB/PseudoCal) | [![Citations](badges/Pseudo-Calibration__Improving_Predictive_Uncertainty_Estimation_in_Unsupervised_Domain_Adaptation.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Pseudo-Calibration%3A+Improving+Predictive+Uncertainty+Estimation+in++Unsupervised+Domain+Adaptation&btnG=) |
|[Learning calibrated uncertainties for domain shift: a distributionally robust learning approach](https://dl.acm.org/doi/abs/10.24963/ijcai.2023/162)| IJCAI | 2023 | [![Star](https://img.shields.io/github/stars/hatchetProject/Deep-Distributionally-Robust-Learning-for-Calibrated-Uncertainties-under-Domain-Shift.svg?style=social&label=Star)](https://github.com/hatchetProject/Deep-Distributionally-Robust-Learning-for-Calibrated-Uncertainties-under-Domain-Shift) | [![Citations](badges/Learning_calibrated_uncertainties_for_domain_shift__a_distributionally_robust_learning_approach.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Learning+Calibrated+Uncertainties+for+Domain+Shift%3A+A+Distributionally+Robust+Learning+Approach&btnG=) |
|[Transferable Calibration with Lower Bias and Variance in Domain Adaptation](https://proceedings.neurips.cc/paper/2020/hash/df12ecd077efc8c23881028604dbb8cc-Abstract.html)| NeurIPS | 2020 | [![Star](https://img.shields.io/github/stars/thuml/TransCal.svg?style=social&label=Star)](https://github.com/thuml/TransCal) | [![Citations](badges/Transferable_Calibration_with_Lower_Bias_and_Variance_in_Domain_Adaptation.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Transferable+Calibration+with+Lower+Bias+and+Variance+in+Domain+Adaptation&btnG=) |
|[Calibrated Prediction with Covariate Shift via Unsupervised Domain Adaptation](https://proceedings.mlr.press/v108/park20b.html)| AISTATS | 2020 | [![Star](https://img.shields.io/github/stars/sangdon/calibration-under-covariateshift.svg?style=social&label=Star)](https://github.com/sangdon/calibration-under-covariateshift) | [![Citations](badges/Calibrated_Prediction_with_Covariate_Shift_via_Unsupervised_Domain_Adaptation.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Calibrated+Prediction+with+Covariate+Shift+via+Unsupervised+Domain+Adaptation&btnG=) |

## Calibration under Joint Shift
| Paper | Source | Year| Code| Citations | 
|-------|-------|-------|-------|:--:|
|[Estimating and Explaining Model Performance When Both Covariates and Labels Shift](https://proceedings.neurips.cc/paper_files/paper/2022/hash/4aa13186c795a52ba88f5b822f4b77eb-Abstract-Conference.html)| NeurIPS | 2022 | [![Star](https://img.shields.io/github/stars/stanford-futuredata/SparseJointShift.svg?style=social&label=Star)](https://github.com/stanford-futuredata/SparseJointShift) | [![Citations](badges/Estimating_and_Explaining_Model_Performance_When_Both_Covariates_and_Labels_Shift.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Estimating+and+Explaining+Model+Performance+When+Both+Covariates+and+Labels+Shift&btnG=) |
|[Factorizable Joint Shift in Multinomial Classification](https://www.mdpi.com/2504-4990/4/3/38)| Machine Learning and Knowledge Extraction | 2022 | None | [![Citations](badges/Factorizable_Joint_Shift_in_Multinomial_Classification.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Factorizable+Joint+Shift+in+Multinomial+Classification&btnG=) |
|[Domain Adaptation with Factorizable Joint Shift](https://arxiv.org/abs/2203.02902)| ICML Workshop | 2021 | None | [![Citations](badges/Domain_Adaptation_with_Factorizable_Joint_Shift.svg)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Domain+Adaptation+with+Factorizable+Joint+Shift&btnG=) |

# How to Update Citations
Run the code:
```python
    Python Fetch_citation.py
